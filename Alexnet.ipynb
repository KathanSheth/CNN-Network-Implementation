{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alexnet Implementation\n",
    "\n",
    "## https://www.nvidia.cn/content/tesla/pdf/machine-learning/imagenet-classification-with-deep-convolutional-nn.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 43 #10,1000 as per dataset\n",
    "\n",
    "features = tf.placeholder(tf.float32,[None,227,227,3])\n",
    "y = tf.placeholder(tf.float32,[None,nb_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"alexnet.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.nn.conv2d(\n",
    "    input,\n",
    "    filter,\n",
    "    strides,\n",
    "    padding,\n",
    "    use_cudnn_on_gpu=True,\n",
    "    data_format='NHWC',\n",
    "    dilations=[1, 1, 1, 1],\n",
    "    name=None\n",
    ")\n",
    "\n",
    "tf.nn.bias_add(\n",
    "    value,\n",
    "    bias,\n",
    "    data_format=None,\n",
    "    name=None\n",
    ")\n",
    "\n",
    "### apply local response normalization to the output.\n",
    "\n",
    "tf.nn.local_response_normalization(\n",
    "    input,\n",
    "    depth_radius=5,\n",
    "    bias=1,\n",
    "    alpha=1,\n",
    "    beta=0.5,\n",
    "    name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Alexnet(features,weights,biases,feature_extract=False):\n",
    "    #If the image is of different size let's say 32X32X3 then it needs to be converted to 227X227X3\n",
    "    #features = tf.image.resize_images(features,(227,227))\n",
    "    features = tf.reshape(features,[-1,227,227,3])\n",
    "    \n",
    "    #1st Convolution Layer\n",
    "    #conv(11, 11, 96, 4, 4, padding='VALID', name='conv1')\n",
    "    conv_1 = tf.nn.conv2d(features,weights['w_1'],strides=[1,4,4,1],padding='SAME',name='conv_1')\n",
    "    conv_1 = tf.nn.bias_add(conv_1,biases['b_1'])\n",
    "    conv_1 = tf.nn.relu(conv_1)\n",
    "    conv_1 = tf.nn.local_response_normalization(conv_1,depth_radius=2.0,bias=1.0,alpha=2e-05,beta=0.75)\n",
    "    # maxpool1\n",
    "    # max_pool(3, 3, 2, 2, padding='VALID', name='pool1')\n",
    "    conv_1 = tf.nn.max_pool(conv_1,ksize=[1,3,3,1],strides=[1,2,2,1],padding='VALID')\n",
    "    \n",
    "    #2nd Convolution Layer\n",
    "    # conv(5, 5, 256, 1, 1, group=2, name='conv2')\n",
    "    conv_2 = tf.nn.conv2d(conv_1,weights['w_2'],strides=[1,1,1,1],padding='SAME',name='conv_2')\n",
    "    conv_2 = tf.nn.bias_add(conv_2,biases['b_2'])\n",
    "    conv_2 = tf.nn.relu(conv_2)\n",
    "    conv_2 = tf.nn.local_response_normalization(conv_2,depth_radius=2.0,bias=1.0,alpha=2e-05,beta=0.75)\n",
    "    # maxpool2\n",
    "    # max_pool(3, 3, 2, 2, padding='VALID', name='pool2')\n",
    "    conv_2 = tf.nn.max_pool(conv_2,ksize=[1,3,3,1],strides=[1,2,2,1],padding='VALID')\n",
    "    \n",
    "    #3rd Convolution Layer\n",
    "    # conv(3, 3, 384, 1, 1, name='conv3')\n",
    "    conv_3 = tf.nn.conv2d(conv_2,weights['w_3'],strides=[1,1,1,1],padding='SAME',name='conv_3')\n",
    "    conv_3 = tf.nn.bias_add(conv_3,biases['b_3'])\n",
    "    conv_3 = tf.nn.relu(conv_3)\n",
    "    \n",
    "    #4rd Convolution Layer\n",
    "    # conv(3, 3, 384, 1, 1, group=2, name='conv4')\n",
    "    conv_4 = tf.nn.conv2d(conv_3,weights['w_4'],strides=[1,1,1,1],padding='SAME',name='conv_4')\n",
    "    conv_4 = tf.nn.bias_add(conv_4,biases['b_4'])\n",
    "    conv_4 = tf.nn.relu(conv_4)\n",
    "    \n",
    "    #5rd Convolution Layer\n",
    "    #conv(3, 3, 256, 1, 1, group=2, name='conv5')\n",
    "    conv_5 = tf.nn.conv2d(conv_4,weights['w_5'],strides=[1,1,1,1],padding='SAME',name='conv_5')\n",
    "    conv_5 = tf.nn.bias_add(conv_5,biases['b_5'])\n",
    "    conv_5 = tf.nn.relu(conv_5)\n",
    "    # maxpool5\n",
    "    # max_pool(3, 3, 2, 2, padding='VALID', name='pool5')\n",
    "   \n",
    "    conv_5 = tf.nn.max_pool(conv_2,ksize=[1,3,3,1],strides=[1,2,2,1],padding='VALID')\n",
    "    \n",
    "    # Flatten the shape of 5th Conv layer for fully connected layer\n",
    "    \n",
    "    flat5 = tf.reshape(conv_5, [-1, int(np.prod(conv_5.get_shape()[1:]))])\n",
    "    \n",
    "    #1st Fully Connected Layer\n",
    "    fc6 = tf.nn.relu(tf.matmul(flat5, weights['wfc_6']) + biases['bfc_6'])\n",
    "    \n",
    "    #2nd Fully Connected Layer\n",
    "    fc7 = tf.nn.relu(tf.matmul(fc6, weights['wfc_7']) + biases['bfc_7'])\n",
    "    \n",
    "    #FOR FEATURE EXTRACTION and WEIGHT FREEZING LOGIC\n",
    "    if feature_extract:\n",
    "        return fc7\n",
    "    \n",
    "    #3rd Fully Connected Layer\n",
    "    fc8 = tf.nn.relu(tf.matmul(fc7, weights['wfc_8']) + biases['bfc_8'])\n",
    "    probabilities = tf.nn.softmax(fc8) #fc8 is logits\n",
    "    \n",
    "    return probabilities\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    \"w_1\":tf.Variable(tf.truncated_normal([11,11,3,96],stddev=1e-2),name='w_1'),\n",
    "    \"w_2\":tf.Variable(tf.truncated_normal([5,5,96,256],stddev=1e-2),name='w_2'),\n",
    "    \"w_3\":tf.Variable(tf.truncated_normal([3,3,256,384],stddev=1e-2),name='w_3'),\n",
    "    \"w_4\":tf.Variable(tf.truncated_normal([3,3,384,384],stddev=1e-2),name='w_4'),\n",
    "    \"w_5\":tf.Variable(tf.truncated_normal([3,3,384,256],stddev=1e-2),name='w_5'),\n",
    "    \"wfc_6\":tf.Variable(tf.truncated_normal([28*28*256,4096],stddev=1e-2),name='wfc_6'),\n",
    "    \"wfc_7\":tf.Variable(tf.truncated_normal([4096,4096],stddev=1e-2),name='wfc_7'),\n",
    "    \"wfc_8\":tf.Variable(tf.truncated_normal([4096,nb_classes],stddev=1e-2),name='wfc_8')\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases = {\n",
    "    \"b_1\":tf.Variable(tf.constant(0.0,shape=[96]),name='b_1'),\n",
    "    \"b_2\":tf.Variable(tf.constant(0.0,shape=[256]),name='b_2'),\n",
    "    \"b_3\":tf.Variable(tf.constant(0.0,shape=[384]),name='b_3'),\n",
    "    \"b_4\":tf.Variable(tf.constant(0.0,shape=[384]),name='b_4'),\n",
    "    \"b_5\":tf.Variable(tf.constant(0.0,shape=[256]),name='b_5'),\n",
    "    \"bfc_6\":tf.Variable(tf.constant(0.0,shape=[4096]),name='bfc_6'),\n",
    "    \"bfc_7\":tf.Variable(tf.constant(0.0,shape=[4096]),name='bfc_7'),\n",
    "    \"bfc_8\":tf.Variable(tf.constant(0.0,shape=[nb_classes]),name='bfc_8')\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
